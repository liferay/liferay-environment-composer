import com.liferay.docker.workspace.environments.Util

import groovy.json.JsonSlurper

import java.nio.file.Files
import java.nio.file.StandardCopyOption

import java.util.Arrays
import java.util.stream.Collectors
import java.util.regex.Matcher
import java.util.regex.Pattern

ext {
	FALSE_SQL_VALUE = config.useDatabaseSQLServer ? "'false'" : "false"
	SSO_CONFIGS = [".ldap.", ".multi.factor.authentication.", ".saml.", ".openid."]
	PROD_ONLY_CONFIGS = [".liferay.analytics.", ".captcha.", ".content.security.policy.", ".elasticsearch7.", ".k8s."]

	clearSingleSignOnConfigurations = {
		String schema ->

		SSO_CONFIGS.each {
			executeSQLQuery("delete from Configuration_ where configurationId like '%${it}%'", schema)
		}

		truncateTables('OpenId%', schema)
		truncateTables('Saml%', schema)

		println "Deleted known problematic single sign on entries from schema ${schema}"
	}

	copyLiferayLXCRepositoryConfiguration = {
		File configFolder, String sourceName, String targetName ->

		File sourceFile = new File(configFolder, sourceName)

		if (!sourceFile.exists()) {
			return false
		}

		File targetFile = file("configs/${targetName}")

		if (sourceFile.isDirectory()) {
			for (String fileName : sourceFile.list()) {
				copyLiferayLXCRepositoryConfiguration(sourceFile, fileName, "${targetName}/${fileName}".toString())
			}
		}
		else {
			targetFile.parentFile.mkdirs()

			Files.copy(sourceFile.toPath(), targetFile.toPath(), StandardCopyOption.REPLACE_EXISTING)
		}

		return true
	}

	copyLiferayLXCRepositoryConfigurations = {
		println ""

		if (config.lxcRepositoryPath == null) {
			println "Unable to copy configurations from LXC repository, because no LXC repository has been set in gradle.properties"

			return
		}

		File lcpJsonFile = new File(config.lxcRepositoryPath, "liferay/LCP.json")

		if (!lcpJsonFile.exists()) {
			println "Unable to copy configurations from LXC repository, because ${config.lxcRepositoryPath} is not the liferay-lxc repository"

			return
		}

		File environmentFolder = null

		if (config.lxcEnvironmentName == null) {
			if (config.defaultCompanyVirtualHost == null) {
				println "Unable to copy configurations from LXC repository, because the company default virtual host is unknown"

				return
			}

			String expectedWebId = config.defaultCompanyVirtualHost["webId"]
			String expectedHostName = config.defaultCompanyVirtualHost["hostname"]

			if (expectedHostName.endsWith(".localhost")) {
				expectedHostName = expectedHostName.substring(0, expectedHostName.length() - ".localhost".length())
			}

			List<File> environmentFolders = fileTree("${config.lxcRepositoryPath}/liferay/configs") {
				"**/portal-env.properties"
			}.filter {
				File envPropertiesFile ->

				(expectedWebId.equals("liferay.com") || envPropertiesFile.text.contains("company.default.web.id=${expectedWebId}")) &&
				envPropertiesFile.text.contains("company.default.virtual.host.name=${expectedHostName}")
			}.collect {
				File envPropertiesFile ->

				envPropertiesFile.parentFile
			}

			if (!environmentFolders.isEmpty()) {
				environmentFolder = environmentFolders.last()
			}

			if (environmentFolder != null) {
				config.lxcEnvironmentName = environmentFolder.name
			}

			if (config.lxcEnvironmentName == null) {
				println "Unable to copy configurations from ${config.lxcRepositoryPath}, because there is no metadata for LXC environment company.default.web.id=${expectedWebId}, company.default.virtual.host.name=${expectedHostName}"

				return
			}
		}
		else {
			environmentFolder = new File(config.lxcRepositoryPath, "liferay/configs/${config.lxcEnvironmentName}")
		}

		if (!environmentFolder.exists()) {
			println "Unable to copy configurations from ${config.lxcRepositoryPath}, because ${environmentFolder.absolutePath} does not exist"

			return
		}

		JsonSlurper jsonSlurper = new JsonSlurper()

		Map<String, String> environmentVariables = jsonSlurper.parse(lcpJsonFile)["environments"][config.lxcEnvironmentName]["env"]

		String jdbcURL = environmentVariables["LIFERAY_JDBC_PERIOD_DEFAULT_PERIOD_URL"]

		if (jdbcURL != null && jdbcURL.startsWith("jdbc:postgresql://")) {
			config.useDatabasePostgreSQL = true

			updateGradleLocalProperties([
				"lr.docker.environment.service.enabled[postgres]": "true"
			])
		}
		else {
			config.useDatabaseMySQL = true

			updateGradleLocalProperties([
				"lr.docker.environment.service.enabled[mysql]": "true"
			])
		}

		if (!config.databasePartitioningEnabled) {
			config.databasePartitioningEnabled = true

			updateGradleLocalProperties(["lr.docker.environment.database.partitioning.enabled": "true"])
		}

		String environment = config.lxcEnvironmentName

		List<String> includeAndOverrideFileNames = ["portal-liferay-online-database-partition.properties"]

		if (copyLiferayLXCRepositoryConfiguration(environmentFolder, "portal-env.properties", "common/properties/lxc-portal-env-${environment}.properties")) {
			includeAndOverrideFileNames.add("./properties/lxc-portal-env-${environment}.properties")

			println "Copied ${environment}/portal-env.properties from ${config.lxcRepositoryPath}"
		}

		if (copyLiferayLXCRepositoryConfiguration(environmentFolder, "scripts", "docker")) {
			println "Copied ${environment}/scripts from ${config.lxcRepositoryPath}"
		}

		if (copyLiferayLXCRepositoryConfiguration(environmentFolder, "osgi", "common/osgi")) {
			println "Copied ${environment}/osgi from ${config.lxcRepositoryPath}"
		}

		file("configs/common/properties/lxc-customer.properties").withOutputStream {
			BufferedOutputStream outputStream ->

			includeAndOverrideFileNames.each {
				String includeAndOverrideFileName ->

				outputStream << "include-and-override=" << includeAndOverrideFileName << "\n"
			}
		}

		String latestReleaseInfoDate = updateGradlePropertiesWithLiferayVersion()

		if (latestReleaseInfoDate != null) {
			println ""
			println "Updated gradle-local.properties to environment dated ${latestReleaseInfoDate}"
		}
	}

	deleteMeantForProductionOnlyConfigurations = {
		String schema ->

		PROD_ONLY_CONFIGS.each {
			executeSQLQuery("delete from Configuration_ where configurationId like '%${it}%'", schema)
		}

		Map<String, String> sanitizedPreferences = [
			"liferayAnalyticsEndpointURL": "fake://fakeAEU",
			"liferayAnalyticsFaroBackendURL": "fake://fakeFBU",
			"liferayAnalyticsURL": "fake://fakeAU",
		]

		sanitizePortalPreferenceValues(schema, sanitizedPreferences)

		println "Deleted known Analytics Cloud, Captcha, CSP, Elasticsearch, Kubernetes entries from schema ${schema}"
	}

	disableUserObjectValidations = {
		String schema ->

		executeSQLQuery("update ObjectValidationRule set active_ = ${FALSE_SQL_VALUE} where objectDefinitionId in (select objectDefinitionId from ObjectDefinition where externalReferenceCode = 'L_USER')", schema)

		println "Disabled object validation users for User system object in schema ${schema}"
	}

	getReleaseInfo = {
		String descriptorText ->

		JsonSlurper jsonSlurper = new JsonSlurper()

		Object environmentDescriptor = jsonSlurper.parseText(descriptorText)

		String liferayImage = environmentDescriptor["liferay-image"]
		String hotfixId = environmentDescriptor["hotfix"]

		Pattern releasePattern = ~'[0-9]+\\.q[1-4]\\.[0-9]+'

		Matcher releaseMatcher = releasePattern.matcher(liferayImage)

		if (!releaseMatcher.find()) {
			println "did not match ${liferayImage}"
			return null
		}

		String release = releaseMatcher.group()

		if ((release.indexOf(".q1") != -1) && !release.startsWith("2024.")) {
			release = release + "-lts"
		}

		String workspaceProduct = "dxp-${release}"

		Map<String, String> releaseInfo = [
			"liferay.workspace.product": workspaceProduct,
			"liferay.workspace.docker.image.liferay": liferayImage,
		]

		if (hotfixId != null && !hotfixId.isEmpty()) {
			releaseInfo["lr.docker.environment.hotfix.urls"] = "https://releases-cdn.liferay.com/dxp/hotfix/${release}/liferay-dxp-${release}-${hotfixId}.zip"
		}

		return releaseInfo
	}

	reactivateDisabledUsers = {
		String schema ->

		executeSQLQuery("update User_ set status = 0", schema)

		executeSQLQuery("update User_ set emailAddress = 'liferaydevsecops@liferay.com', screenName='liferaydevsecops', firstName='Liferay', lastName='DevSecOps' where emailAddress = 'test@lxc.app' and screenName = 'test'", schema)

		println "Re-activated all users in schema ${schema}"
	}

	replaceUserPasswords = {
		String schema ->

		executeSQLQuery("update User_ set password_ = '${config.liferayUserPassword}', passwordEncrypted = false, passwordReset = false, lockout = false", schema)

		println "Reset all user passwords to '${config.liferayUserPassword}' in schema ${schema}"
	}

	sanitizeMailConfigurations = {
		String schema ->

		Map<String, String> sanitizedPreferences = [
			"mail.session.mail.pop3.host": "fake-pop3-host",
			"mail.session.mail.smtp.host": "fake-smtp-host",
			"mail.session.mail.pop3.user": "fake-pop3-user",
			"mail.session.mail.smtp.user": "fake-stmp-host",
			"mail.session.mail.pop3.password": "fake-pop3-password",
			"mail.session.mail.smtp.password": "fake-smtp-password",
			"mail.session.mail": "false",
			"pop.server.notifications.enabled": "false"
		]

		sanitizePortalPreferenceValues(schema, sanitizedPreferences)

		executeSQLQuery("update MBMailingList set inServerName = 'fake-pop3-host', outServerName = 'fake-smtp-host', inPassword = 'fake-pop3-password', outPassword = 'fake-smtp-password', active_ = ${FALSE_SQL_VALUE}", schema)

		println "Sanitized known POP and SMTP configurations in schema ${schema}"
	}

	sanitizePortalPreferenceValues = {
		schema, Map<String, String> sanitizedValues ->

		sanitizedValues.each {
			Map.Entry<String, String> entry ->

			executeSQLQuery("update PortalPreferenceValue set smallValue = '${entry.value}' where key_ = '${entry.key}'", schema)
		}
	}

	truncateTables = {
		String tableNamePattern, String schema ->

		List<Map<String, String>> tableNames

		if (config.useDatabaseDB2) {
			tableNames = executeSQLQuery("select TABLE_NAME from sysibm.tables WHERE TABLE_CATALOG = '" + schema.toUpperCase() + "' and TABLE_NAME like '${tableNamePattern}' OR TABLE_NAME like '${tableNamePattern.toLowerCase()}'", schema)
		}
		else {
			tableNames = executeSQLQuery("select TABLE_NAME from information_schema.TABLES WHERE TABLE_SCHEMA = '${schema}' and TABLE_NAME like '${tableNamePattern}' OR TABLE_NAME like '${tableNamePattern.toLowerCase()}'", schema)
		}

		tableNames.each {
			Map<String, String> resultRow ->

			executeSQLQuery("truncate table ${resultRow.get("TABLE_NAME")}", schema)
		}
	}

	updateDatabaseForLocalDevelopment = {
		forEachCompanyId {
			String companyId, String hostname, String webId, String schema ->

			replaceUserPasswords(schema)
			clearSingleSignOnConfigurations(schema)
			reactivateDisabledUsers(schema)
			disableUserObjectValidations(schema)
			sanitizeMailConfigurations(schema)
			deleteMeantForProductionOnlyConfigurations(schema)
		}

		updateVirtualHosts()
	}

	updateGradlePropertiesWithLiferayVersion = {
		String environment = config.lxcEnvironmentName

		File lxcRepositoryFolder = file(config.lxcRepositoryPath)
		String descriptorPath = "automation/environment-descriptors/${environment}.json"

		File environmentDescriptorFile = new File(lxcRepositoryFolder, descriptorPath)

		if (!environmentDescriptorFile.exists()) {
			return null
		}

		Map<String, String> latestReleaseInfo = null
		String latestReleaseInfoDate = null

		waitForCommand("git log -5 --pretty='%H %cd' --date=format-local:'%Y-%m-%d %H:%M:%S %Z' --simplify-by-decoration -- ${descriptorPath}", lxcRepositoryFolder).eachLine {
			String line ->

			int pos = line.indexOf(" ")

			String commit = line.substring(0, pos)
			String releaseInfoDate = line.substring(pos + 1)

			println ""
			println releaseInfoDate

			Map<String, String> releaseInfo = getReleaseInfo(waitForCommand("git show ${commit}:${descriptorPath}", lxcRepositoryFolder)).each {
				Map.Entry<String, String> entry ->

				println entry
			}

			if (latestReleaseInfo == null) {
				latestReleaseInfo = releaseInfo
				latestReleaseInfoDate = releaseInfoDate
			}
		}

		if (latestReleaseInfo != null) {
			latestReleaseInfo.put("lr.docker.environment.lxc.environment.name", environment)

			String product = latestReleaseInfo["liferay.workspace.product"]

			if (product != null && !product.equals(config.product)) {
				config.product = product
				project.gradle.liferayWorkspace.product = product
			}

			String dockerImageLiferay = latestReleaseInfo["liferay.workspace.docker.image.liferay"]

			if (dockerImageLiferay != null && !dockerImageLiferay.equals(config.dockerImageLiferay)) {
				config.dockerImageLiferay = dockerImageLiferay
				project.gradle.liferayWorkspace.dockerImageLiferay = dockerImageLiferay
			}

			String hotfixURL = latestReleaseInfo["lr.docker.environment.hotfix.urls"]

			if (hotfixURL != null && !config.hotfixURLs.contains(hotfixURL)) {
				config.hotfixURLs.add(hotfixURL)
			}

			updateGradleLocalProperties(latestReleaseInfo)
		}

		return latestReleaseInfoDate
	}

	updateLXCRepository = {
		File lxcRepositoryFolder = file(config.lxcRepositoryPath)

		String repoURL = "git@github.com:liferay/liferay-lxc.git"

		if (waitForCommand("git remote -v", lxcRepositoryFolder).readLines().any { it.contains(repoURL) }) {
			println "Updating the liferay-lxc repo..."
			waitForCommand("git pull --rebase ${repoURL} master", lxcRepositoryFolder)
		}
	}

	updateVirtualHosts = {
		executeSQLQuery("update VirtualHost set hostname = concat(hostname, '.localhost') where hostname <> 'localhost' and hostname not like '%.localhost'", config.databaseName)

		println "Added .localhost to the end of all virtual host names that were not localhost"
	}
}

tasks.register("addCloudSQLScriptToDumpsVolume") {
	dependsOn ":copyDumpsFilesToDumpsVolume"

	onlyIf("using MySQL or PostgreSQL") {
		config.useDatabaseMySQL || config.useDatabasePostgreSQL
	}
	onlyIf("there is a database dump file") {
		!Util.isEmpty(project.fileTree("dumps"))
	}

	doLast {
		File globalVariableScript = file("dumps/0.sql")

		if (config.useDatabaseMySQL) {
			Map<String, String> newVariables = [
				"max_allowed_packet": String.valueOf(1L << 30),
				"autocommit": "0",
				"unique_checks": "0",
				"foreign_key_checks": "0",
				"innodb_stats_auto_recalc": "0",
			]

			globalVariableScript.withOutputStream {
				BufferedOutputStream initSQLOutputStream ->

				initSQLOutputStream << newVariables.collect {
					Map.Entry<String, String> entry ->

					"SET GLOBAL ${entry.key}=${entry.value};"
				}.join("\n") << ";"

				initSQLOutputStream << ["lportal", "dxpcloud", "cloudsqlimport"].collect {
					String userName ->

					"create user if not exists ${userName} identified by 'lportal';\ngrant all on *.* to '${userName}'@'%';\n"
				}.join("\n")
			}
		}
		else {
			globalVariableScript.withOutputStream {
				BufferedOutputStream initSQLOutputStream ->

				initSQLOutputStream << "create role cloudsqlsuperuser with login superuser password 'lportal';"
			}
		}
	}
}

tasks.register("copyLiferayLXCRepositoryConfigurations") {
	dependsOn ":updateLXCRepository"

	doFirst {
		copyLiferayLXCRepositoryConfigurations();
	}
}

tasks.register("importPostgreSQLBinaryDump") {
	dependsOn ":copyDumpsFilesToDumpsVolume"
	dependsOn ":decompressArchiveFilesInDumpsVolume"

	onlyIf("using PostgreSQL database") {
		config.useDatabasePostgreSQL
	}

	doLast {
		String[] backupFileNames = waitForCommand("docker compose exec database ls /docker-entrypoint-initdb.d").split("\s+")

		String[] binaryDumpFileNames = Arrays.stream(backupFileNames)
			.filter(fileName -> fileName.endsWith(".dump") || file.endsWith(".dmp"))
			.toArray(String[]::new)

		if (binaryDumpFileNames.length > 1) {
			throw new GradleException("Aborting because multiple binary dump files were found in the dumps folder.")
		}

		if (binaryDumpFileNames.length > 0) {
			String databaseInitialized = executeSQLQuery("SELECT * from pg_tables WHERE schemaname NOT LIKE 'pg_%' AND schemaname NOT LIKE 'sql_%' AND schemaname NOT LIKE 'information_schema'")

			if (databaseInitialized.trim() == "[]") {
				println "Attempting to restore binary dump file: ${binaryDumpFiles[0].name} with database name: ${config.databaseName}..."

				waitForCommand("docker compose exec -u postgres database pg_restore -v -U liferay -d ${config.databaseName} /docker-entrypoint-initdb.d/${binaryDumpFiles[0].name}")
			} else {
				println "Database ${config.databaseName} already initialized, skipping dump binary restore."
			}
		}
	}
}

tasks.register("prepareArchivedSQLFiles") {
	onlyIf("there is a database dump file") {
		!Util.isEmpty(project.fileTree("dumps"))
	}
	onlyIf("using MariaDB, MySQL, or PostgreSQL") {
		config.useDatabaseMariaDB || config.useDatabaseMySQL || config.useDatabasePostgreSQL
	}

	doFirst {
		project.fileTree("dumps") {
			include "**/*.gz"
			include "**/*.bz2"
			exclude "**/.gitkeep"
		}.forEach {
			File dumpFile ->

			String oldPath = dumpFile.absolutePath
			String newPath = null

			String dumpFileName = dumpFile.name

			if (dumpFileName.matches(/.*\.(bz2|gz)/) && !dumpFileName.matches(/.*\.sql\.(bz2|gz)/)) {
				String fileExtension = oldPath.split(/\./)[-1]

				newPath = oldPath.replace(fileExtension, ".sql.${fileExtension}")
			}
			else if (!dumpFileName.contains(".")) {
				newPath = "${dumpFile.absolutePath}.sql"
			}

			if (newPath != null) {
				dumpFile.renameTo(newPath)
			}
		}
	}
}

tasks.register("resetDatabaseGlobalValues") {
	dependsOn ":copyDumpsFilesToDumpsVolume"
	dependsOn ":decompressArchiveFilesInDumpsVolume"

	onlyIf("using a MySQL or MariaDB database") {
		config.useDatabaseMariaDB || config.useDatabaseMySQL
	}

	doLast {
		Map<String, String> oldVariables = [
			"max_allowed_packet": String.valueOf(1L << 26),
			"autocommit": "1",
			"unique_checks": "1",
			"foreign_key_checks": "1",
			"innodb_stats_auto_recalc": "1",
		]

		String query = oldVariables.collect {
			Map.Entry<String, String> oldVariable ->

			"SET GLOBAL ${oldVariable.key}=${oldVariable.value};\n"
		}.join("")

		executeSQLQuery(query)
	}
}

tasks.register("prepareDatabaseForLocalDevelopment") {
	dependsOn ":copyDumpsFilesToDumpsVolume"
	dependsOn ":decompressArchiveFilesInDumpsVolume"

	mustRunAfter ":resetDatabaseGlobalValues"
	mustRunAfter ":importPostgreSQLBinaryDump"

	onlyIf("using an external database") {
		config.useDatabase
	}
	onlyIf("there is a database dump file") {
		!Util.isEmpty(project.fileTree("dumps"))
	}

	doFirst {
		println "Attempting to update database for local development"

		updateDatabaseForLocalDevelopment()
	}
}

tasks.register("decompressArchiveFilesInDumpsVolume") {
	dependsOn ":copyDumpsFilesToDumpsVolume"

	onlyIf("using an external database") {
		config.useDatabase
	}
	onlyIf("there is a database dump file") {
		!Util.isEmpty(project.fileTree("dumps"))
	}

	doLast {
		List<File> dumpFiles = project.fileTree("dumps").files.stream().filter(
			file -> file.name.toString() != ".gitkeep"
		).collect(Collectors.toList())

		List<File> archiveFiles = dumpFiles.findAll {
			file -> file.name.matches(/.*\.(gz|tar\.gz|tgz|bz2|tar\.bz2|tbz|zip|7z)/)
		}

		if (archiveFiles.size() == 0) {
			return
		}

		File archiveFile = archiveFiles[0]

		String archiveFileName = archiveFile.name

		String userString = config.useDatabaseSQLServer ? "--user 10001:10001" : ""

		println "Decompressing database archive file into dumps volume"

		String dumpsVolumeName = "${config.namespace}_dumps"

		if (archiveFileName.endsWith("zip") || archiveFileName.endsWith("7z")) {
			boolean isEncrypted = waitForCommand("docker run --rm ${userString} -v ${dumpsVolumeName}:/target backplane/7z:latest l -slt /target/${archiveFileName}").contains("Encrypted = +")

			String lxcBackupPassword = ""

			if (isEncrypted) {
				if (!config.lxcBackupPassword) {
					throw new GradleException("failed to decrypt archive as no LXC backup password as provided")
				}

				lxcBackupPassword = config.lxcBackupPassword
			}

			waitForCommand("docker run --rm ${userString} -v ${dumpsVolumeName}:/target backplane/7z:latest x -aos /target/${archiveFileName} -o/target -p${lxcBackupPassword}")
		}

		String busyboxCommand = ""

		if (archiveFileName.endsWith("tar.gz") || archiveFileName.endsWith("tgz")) {
			busyboxCommand = "tar xzf /target/${archiveFileName} -C /target"
		}
		else if (archiveFileName.endsWith("gz")) {
			busyboxCommand = "gzip -d /target/${archiveFileName}"
		}

		if (archiveFileName.endsWith("tar.bz2") || archiveFileName.endsWith("tbz")) {
			busyboxCommand = "tar xjf /target/${archiveFileName} -C /target"
		}
		else if (archiveFileName.endsWith("bz2")) {
			busyboxCommand = "bzip2 -d /target/${archiveFileName}"
		}

		if (archiveFileName.endsWith("tar")) {
			busyboxCommand = "tar xf /target/${archiveFileName} -C /target"
		}

		if (busyboxCommand != "") {
			waitForCommand("docker run --rm ${userString} -v ${dumpsVolumeName}:/target busybox:latest sh -c '${busyboxCommand}'")
		}

		waitForCommand("docker run --rm ${userString} -v ${dumpsVolumeName}:/target busybox:latest sh -c 'rm -rf /target/${archiveFileName}'")

		waitForContainer("database")
	}
}

tasks.register("copyDumpsFilesToDumpsVolume") {
	dependsOn ":prepareArchivedSQLFiles"

	onlyIf("using an external database") {
		config.useDatabase
	}
	onlyIf("there is a database dump file") {
		!Util.isEmpty(project.fileTree("dumps"))
	}

	doLast {
		FileCollection backupFiles = project.fileTree(config.dataDirectory)

		if (config.dataDirectory != null && !config.dataDirectory.isEmpty() && !Util.isEmpty(backupFiles)) {
			println "Skipping database dumps import because a data backup will be imported from ${config.dataDirectory}"

			return;
		}

		List<File> dumpFiles = project.fileTree("dumps").files.stream().filter(
			file -> file.name.toString() != ".gitkeep"
		).collect(Collectors.toList())

		List<File> archiveFiles = dumpFiles.findAll {
			file -> file.name.matches(/.*\.(gz|tar\.gz|tgz|bz2|tar\.bz2|tbz|zip|7z)/)
		}

		if (archiveFiles.size() > 1) {
			throw new GradleException("failed to prepare dumps volume as multiple archive files were found in dumps directory")
		}

		String dumpsVolumeName = "${config.namespace}_dumps"

		if (getExistingVolumeNames().contains(dumpsVolumeName)) {
			waitForCommand("docker compose down database")
			waitForCommand("docker volume rm ${dumpsVolumeName}")
		}

		waitForCommand("docker compose build database")
		waitForCommand("docker compose create database")

		if (archiveFiles.size() == 0) {
			println "Copying raw database files into dumps volume"

			if (config.useDatabaseSQLServer) {
				List<File> db2BackupFiles = dumpFiles.findAll {
					file -> file.name.matches(/.*\.(bacpac|bak)/)
				}

				if (db2BackupFiles.size() > 1) {
					throw new GradleException("Aborting because multiple binary dump files were found in the dumps folder.")
				}
			}

			dumpFiles.each {
				File dumpFile ->

				addToVolume(dumpsVolumeName, dumpFile)
			}

			return
		}

		println "Copying database archive file into dumps volume"

		addToVolume(dumpsVolumeName, archiveFiles[0])
	}
}

tasks.register("updateLXCRepository") {
	onlyIf("LXC repo is configured") {
		if (config.lxcRepositoryPath == null) {
			return false
		}

		if (config.lxcRepositoryPath == "") {
			return false
		}

		return file(config.lxcRepositoryPath).exists()
	}

	doFirst {
		updateLXCRepository()
	}
}

project.plugins.apply "docker-common"