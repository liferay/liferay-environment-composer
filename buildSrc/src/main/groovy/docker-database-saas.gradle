import com.liferay.docker.workspace.environments.Util

ext {
	SSO_CONFIGS = [".ldap.", ".multi.factor.authentication.", ".saml.", ".openid."]
	PROD_ONLY_CONFIGS = [".liferay.analytics.", ".captcha.", ".content.security.policy.", ".elasticsearch7.", ".k8s."]

	clearSingleSignOnConfigurations = {
		String schema ->

		SSO_CONFIGS.each {
			executeSQLQuery("delete from Configuration_ where configurationId like '%${it}%'", schema)
		}

		truncateTables('OpenId%', schema)
		truncateTables('Saml%', schema)

		println "Deleted known problematic single sign on entries from schema ${schema}"
	}

	deleteMeantForProductionOnlyConfigurations = {
		String schema ->

		PROD_ONLY_CONFIGS.each {
			executeSQLQuery("delete from Configuration_ where configurationId like '%${it}%'", schema)
		}

		Map<String, String> sanitizedPreferences = [
			"liferayAnalyticsEndpointURL": "fake://fakeAEU",
			"liferayAnalyticsFaroBackendURL": "fake://fakeFBU",
			"liferayAnalyticsURL": "fake://fakeAU",
		]

		sanitizePortalPreferenceValues(schema, sanitizedPreferences)

		println "Deleted known Analytics Cloud, Captcha, CSP, Elasticsearch, Kubernetes entries from schema ${schema}"
	}

	disableUserObjectValidations = {
		String schema ->

		executeSQLQuery("update ObjectValidationRule set active_ = false where objectDefinitionId in (select objectDefinitionId from ObjectDefinition where externalReferenceCode = 'L_USER')", schema)

		println "Disabled object validation users for User system object in schema ${schema}"
	}

	reactivateDisabledUsers = {
		String schema ->

		executeSQLQuery("update User_ set status = 0", schema)

		executeSQLQuery("update User_ set emailAddress = 'liferaydevsecops@liferay.com', screenName='liferaydevsecops', firstName='Liferay', lastName='DevSecOps' where emailAddress = 'test@lxc.app' and screenName = 'test'", schema)

		println "Re-activated all users in schema ${schema}"
	}

	replaceUserPasswords = {
		String schema ->

		executeSQLQuery("update User_ set password_ = '${config.liferayUserPassword}', passwordEncrypted = false, passwordReset = false, lockout = false", schema)

		println "Reset all user passwords to '${config.liferayUserPassword}' in schema ${schema}"
	}

	sanitizeMailConfigurations = {
		String schema ->

		Map<String, String> sanitizedPreferences = [
			"mail.session.mail.pop3.host": "fake-pop3-host",
			"mail.session.mail.smtp.host": "fake-smtp-host",
			"mail.session.mail.pop3.user": "fake-pop3-user",
			"mail.session.mail.smtp.user": "fake-stmp-host",
			"mail.session.mail.pop3.password": "fake-pop3-password",
			"mail.session.mail.smtp.password": "fake-smtp-password",
			"mail.session.mail": "false",
			"pop.server.notifications.enabled": "false"
		]

		sanitizePortalPreferenceValues(schema, sanitizedPreferences)

		executeSQLQuery("update MBMailingList set inServerName = 'fake-pop3-host', outServerName = 'fake-smtp-host', inPassword = 'fake-pop3-password', outPassword = 'fake-smtp-password', active_ = false", schema)

		println "Sanitized known POP and SMTP configurations in schema ${schema}"
	}

	sanitizePortalPreferenceValues = {
		schema, Map<String, String> sanitizedValues ->

		sanitizedValues.each {
			Map.Entry<String, String> entry ->

			executeSQLQuery("update PortalPreferenceValue set smallValue = '${entry.value}' where key_ = '${entry.key}'", schema)
		}
	}

	truncateTables = {
		String tableNamePattern, String schema ->

		List<Map<String, String>> tableNames = executeSQLQuery("select TABLE_NAME from information_schema.TABLES WHERE TABLE_SCHEMA = '${schema}' and TABLE_NAME like '${tableNamePattern}' OR TABLE_NAME like '${tableNamePattern.toLowerCase()}'", schema)

		tableNames.each {
			Map<String, String> resultRow ->

			executeSQLQuery("truncate table ${resultRow.get("TABLE_NAME")}", schema)
		}
	}

	updateDatabaseForLocalDevelopment = {
		forEachCompanyId {
			String companyId, String hostname, String webId, String schema ->

			replaceUserPasswords(schema)
			clearSingleSignOnConfigurations(schema)
			reactivateDisabledUsers(schema)
			disableUserObjectValidations(schema)
			sanitizeMailConfigurations(schema)
			deleteMeantForProductionOnlyConfigurations(schema)
		}

		updateVirtualHosts()
	}

	updateVirtualHosts = {
		executeSQLQuery("update VirtualHost set hostname = concat(hostname, '.localhost') where hostname <> 'localhost' and hostname not like '%.localhost'", config.databaseName)

		println "Added .localhost to the end of all virtual host names that were not localhost"
	}
}

tasks.register("decryptCloudBackupDatabase") {
	onlyIf("using an external database") {
		config.useDatabase
	}
	onlyIf("there is a database dump file") {
		!Util.isEmpty(project.fileTree("dumps"))
	}

	doFirst {
		FileCollection decryptedBackups = project.fileTree("dumps") {
			include "**/*.sql"
			include "**/*.sql.gz"
			include "**/*.gz"
		}

		if (!Util.isEmpty(decryptedBackups)) {
			print("Found existing unencrypted backups in dumps/ folder")

			return
		}

		FileCollection encryptedBackups = project.fileTree("dumps") {
			include "*.7z"
			exclude "*doclib*"
		}

		if (Util.isEmpty(encryptedBackups)) {
			encryptedBackups = project.fileTree("dumps") {
				include "*.zip"
				exclude "*doclib*"
			}
		}

		if (encryptedBackups.isEmpty()) {
			return
		}
		else if (encryptedBackups.size() != 1) {
			throw new GradleException("Aborting because multiple potential backups where found in the dumps/ folder")
		}

		if (config.lxcBackupPassword != null && config.lxcBackupPassword.length() > 0) {
			println "Extracting LXC database backup (using password specified in gradle.properties)"

			waitForCommand("7z x -aos ${encryptedBackups[0].absolutePath} -odumps/ -p${config.lxcBackupPassword}")
		}
		else {
			println "Extracting LXC database backup (assuming no password, because none was set in gradle.properties)"

			waitForCommand("7z x -aos ${encryptedBackups[0].absolutePath} -odumps/ -p")
		}
	}
}

tasks.register("copyDatabaseDumpsToDumpsVolume") {
	dependsOn ":decryptCloudBackupDatabase"

	onlyIf("using an external database") {
		config.useDatabase
	}
	onlyIf("there is a database dump file") {
		!Util.isEmpty(project.fileTree("dumps"))
	}

	doFirst {
		FileCollection backupFiles = project.fileTree(config.dataDirectory)

		if (config.dataDirectory != null && !config.dataDirectory.isEmpty() && !Util.isEmpty(backupFiles)) {
			return;
		}

		String dumpsVolumeName = "${config.namespace}_dumps"

		if (getExistingVolumeNames().contains(dumpsVolumeName)) {
			waitForCommand("docker compose down database")
			waitForCommand("docker volume rm ${dumpsVolumeName}")
		}

		waitForCommand("docker compose build database")
		waitForCommand("docker compose create database")

		fileTree("dumps") {
			include "**/*.sql"
			include "**/*.sql.gz"
			include "**/*.gz"
		}.forEach {
			File dumpFile ->

			println dumpFile

			String oldPath = dumpFile.absolutePath
			String newPath = null

			if (dumpFile.name.endsWith(".gz") && !dumpFile.name.endsWith(".sql.gz")) {
				newPath = "${oldPath.substring(0, oldPath.length() - 3)}.sql.gz"
			}
			else if (!dumpFile.name.contains(".")) {
				newPath = "${dumpFile.absolutePath}.sql"
			}

			if (newPath != null) {
				dumpFile.renameTo(newPath)
				dumpFile = file(newPath)
			}

			addToVolume(dumpsVolumeName, dumpFile)
		}

		println "Loading database backup into database dumps volume"

		File globalVariableScript = file("0.sql")

		Map<String, String> oldVariables = [
			"max_allowed_packet": String.valueOf(1L << 26),
			"autocommit": "1",
			"unique_checks": "1",
			"foreign_key_checks": "1",
			"innodb_stats_auto_recalc": "1",
		]

		if (config.useDatabaseMySQL) {
			Map<String, String> newVariables = [
				"max_allowed_packet": String.valueOf(1L << 30),
				"autocommit": "0",
				"unique_checks": "0",
				"foreign_key_checks": "0",
				"innodb_stats_auto_recalc": "0",
			]

			globalVariableScript.withOutputStream {
				BufferedOutputStream initSQLOutputStream ->

				initSQLOutputStream << newVariables.collect {
					Map.Entry<String, String> entry ->

					"SET GLOBAL ${entry.key}=${entry.value};"
				}.join("\n") << ";"

				initSQLOutputStream << ["lportal", "dxpcloud", "cloudsqlimport"].collect {
					String userName ->

					"create user if not exists ${userName} identified by 'lportal';\ngrant all on *.* to '${userName}'@'%';\n"
				}.join("\n")
			}
		}
		else if (config.useDatabasePostgreSQL) {
			globalVariableScript.withOutputStream {
				BufferedOutputStream initSQLOutputStream ->

				initSQLOutputStream << "create role cloudsqlsuperuser with login superuser password 'lportal';"
			}
		}

		if (globalVariableScript.exists()) {
			addToVolume(dumpsVolumeName, globalVariableScript)

			globalVariableScript.delete()
		}
	}
}

tasks.register("importDatabaseDumps") {
	dependsOn ":copyDatabaseDumpsToDumpsVolume"

	onlyIf("using an external database") {
		config.useDatabase
	}
	onlyIf("there is a database dump file") {
		!Util.isEmpty(project.fileTree("dumps"))
	}

	doFirst {
		FileCollection backupFiles = project.fileTree(config.dataDirectory)

		if (config.dataDirectory != null && !config.dataDirectory.isEmpty() && !Util.isEmpty(backupFiles)) {
			println "Skipping database dumps import because a data backup will be imported from ${config.dataDirectory}"

			return;
		}

		println "Initializing database via first start scripts"

		waitForContainer("database", config.dockerContainerDatabase)

		if (config.useDatabaseMySQL) {
			String query = oldVariables.collect {
				Map.Entry<String, String> oldVariable ->

				"SET GLOBAL ${oldVariable.key}=${oldVariable.value};\n"
			}.join("")

			executeSQLQuery(query)
		}

		println "Attempting to update database for local development"

		updateDatabaseForLocalDevelopment()
	}
}

project.plugins.apply "docker-common"